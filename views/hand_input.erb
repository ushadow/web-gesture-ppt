<!DOCTYPE html>
<html>
  <head>
    <title>Kinect Hand Input</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0, 
    maximum-scale=1.0, user-scalable=no"/>
    <link rel="stylesheet" href="application.css" type="text/css" />
    <link rel="stylesheet" href="css/reveal.min.css"/>
    <link rel="stylesheet" href="css/theme/default.css" id="theme"/>
    <script src="js/jquery.js" type="text/javascript"></script>
    <script src="application.js" type="text/javascript"></script>
  </head>
  <body>
    <div class="reveal">
      <button>Connect</button>
      <input id="ws-addr" type="text" value="127.0.0.1:8080"/>
      <label id="status-label" class="status">Status:</label>
      <span id="status-text"></span>
      <div class="slides">
        <section>
          <h1>Real-time Gesture Recognition for Natural Multimodal 
            Interaction</h1>
          <h2>Ying Yin</h2>
        </section>
        <section>
          <video controls preload="auto">
          <source src="media/video/kinect.mp4" type="video/mp4">
          </video>
        </section>
        <section>
          <video width="1280" height="720" controls preload="auto">
          <source src="media/video/ironman_short.mp4" type="video/mp4"> 
          </video>
        </section>
        <section data-transition="none">
          <img src="media/taxonomy.jpg"/>
        </section>
        <section data-transition="none">
          <img src="media/taxonomy1.jpg"/>
        </section>
        <section data-transition="none">
          <img src="media/taxonomy2.jpg"/>
        </section>
        <section>
          <h2>Temporal Model of Gestures</h2>
          <p>Pre-stroke -&gt; Nucleus -&gt; Post-stroke</p>
          <video muted controls loop preload="auto">
          <source src="media/video/gesture_temporal.mp4" type="video/mp4"> 
          </video>
        </section>
        <section>
        <h2>Contributions</h2>
        <ul>
          <li>Human computer interaction
            <ul class="fragment">
              <li>Smoothly handles <em>path</em> and <em>pose</em> gestures</li>
              <li>Responds to <em>discrete</em> and <em>continous</em> flow gestures appropriately and promptly</li>
            </ul>
          </li>
          <li>Machine learning
            <ul class="fragment">
              <li>Probabilistic model that unifies recognition of two forms of gestures</li>
              <li>Use hidden states to identify gesture phases</li>
              <li>Efficient online inference to achieve a balance between accuracy and responsiveness</li>
            </u>
          </li>
        </ul>
        </section>
        <section>
          <section data-transition="none">
            <h2>System Overview</h2>
            <img src="media/system_overview.jpg"/>
          </section>
          <section data-transition="none">
            <h2>System Overview</h2>
            <img src="media/system_overview_tracking.jpg"/>
          </section>
        </section>
        <section>
          <section>
            <h2>Horizontal Display</h2>
            <img src="media/tabletop.jpg"/>
          </section>
          <section data-transition="none">
            <img src="media/handtracking.JPG"/>
          </section>
          <section data-transition="none">
            <video data-autoplay>
            <source src="media/video/pointing.mp4" type="video/mp4">
            </video>
          </section>
        </section>
        <section>
          <section data-transition="none">
            <h2>Vertical Display</h2>
            <p>Gesture Salience Detection [ICMI'13]</p>
            <img src="media/gesture_salience.png"/>
          </section>
          <section data-transition="none">
            <h2>Vertical Display</h2>
            <p>Gesture Salience Detection [ICMI'13]</p>
            <video data-autoplay>
            <source src="media/video/chairgest_handtracking.mp4" type="video/mp4">
            </video>
          </section>
        </section>
        <section>
          <section>
            <img src="media/system_overview_feature.jpg"/>
          </section>
          <section>
            <h2>Feature Vector</h2>
            <ul>
              <li>Motion feature
                <ul>
                  <li>Relative position, velocity, acceleration</li>
                </ul>
              </li>
              <li>Hand pose feature
                <ul>
                  <li>Histogram of oriented gradients (HOG) from depth data</li>
                  <li>Principal component analysis (PCA) dimention reduction</li>
                </ul>
              </li>
            </ul>
            <p></p>
          </section>
          <section>
            <img src="media/hog.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Feature Vector</h2>
            <div>
            $$\underline{x}_t = \left[ \begin{array}{c}
            \underline{x}_t^M \\
            \underline{x}_t^H \\ \end{array}\right] \in \mathbb{R}^d$$
            </div>
          </section>
        </section>
        <section>
          <section>
            <img src="media/system_overview_recognition.jpg"/>
          </section>
          <section>
            <h2>Gesture Recognition</h2>
            <ul>
              <li>Offline recognition [ICMI'13]
              <ul>
                <li>Segmentation</li>
                <li>Classification</li>
              </ul>
              <li class="fragment grow">Online real-time recognition [VL/HCC'14]
                <ul>
                  <li><em>Simultaneous</em> segmentation and recognition</li>
                  <li>Unified probabilistic model</li>
                </ul>
              </li>
            </ul>
          </section>
          <section>
            <h2>Why Unified Model</h2>
            <ul>
              <li>Previous work
                <ul>
                  <li><em>Path</em> gestures: HMM or HCRF</li>
                  <li><em>Pose</em> gestures: HOG and SVM</li>
                </ul>
              </li>
              <li class="fragment">Possible approaches to combine both 
                <ul>
                  <li>Classify form first and use different methods
                    <ul>
                      <li class="fragment"><em class="highlight-red">Make early decistions that are hard to correct later</em></li>
                    </ul>
                  </li>
                  <li class="fragment">Apply different methods concurrently 
                  and compare probabilities
                    <ul>
                      <li class="fragment"><em class="highlight-red">How to compare probabilities from two different models?</em></li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li class="fragment"><em class="highlight-green">Unified probabilistic model 
                based on hierarchical HMM</em>
                <ul>
                  <li><em class="highlight-green">Different topologies for
                    different <em>forms</em></em></li>
                  <li><em class="highlight-green">Comparable probabilities
                  </em></li>
                  <li><em class="highlight-green">Make soft decisions and propagate posterior probabilities</em>
                  <li><em class="highlight-green">Until a response is required according to gesture <em>flow</em></em></li>
                </ul>
              </li>
            </ul>
          </section>
        </section>
        <section>
          <section data-transition="none">
          <h2>Hierarchical Hidden Markov Model</h2>
          <img src="media/phase_hmm.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Hierarchical Hidden Markov Model</h2>
          <img src="media/phase_hhmm.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Hierarchical Hidden Markov Model</h2>
          <img src="media/phase_hhmm_obs.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Hierarchical Hidden Markov Model</h2>
          <p>Combine different gestures</p>
          <img src="media/combined.jpg"/>
          </section>
        </section>
        <section>
          <section>
            <h2>Unified Model</h2>
            <ul>
              <li>Train one model per gesture: <em>path</em> and <em>pose</em> gestures</li>
                <ul>
                  <li>With different topologies</li>
                </ul>
              </li>
              <li>Combined the model into a HHMM and flatten into HMM</li>
              <li>Fast online inference</li>
            </ul>
          </section>
          <section data-transition="none">
            <h2>Path Gestures</h2>
            <img src="media/phase_hhmm_obs.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Path Gestures</h2>
            <img src="media/embedded.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Path Gestures</h2>
            <img src="media/embedded_prob.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Feature Distributions - Motion</h2>
            <img src="media/motion_hist.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Feature Distributions - Hand Pose</h2>
            <img src="media/hist_pca.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Path Gestures</h2>
            <img src="media/embedded_gmm.jpg"/>
          </section>
        </section>
        <section>
          <section>
            <h2>Path Gesture</h2>
            <ul>
              <li>Training strategies</li>
              <ul>
                <li>Embedded training</li>
                <li>Two-pass training
                  <ol>
                    <li>Viterbi alignment</li>
                    <li>Baum-Welch expectation maximization</li>
                  </ol>
                </li>
              </ul>
            </ul>
          </section>
          <section data-transition="none">
            <img src="media/training1.jpg"/>
          </section>
          <section data-transition="none">
            <img src="media/training2.jpg"/>
          </section>
          <section data-transition="none">
            <img src="media/training3.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Path Gesture</h2>
            <ul>
              <li>Training strategies</li>
              <ul>
                <li>Embedded training</li>
                <li>Two-pass training
                  <ol>
                    <li>Viterbi alignment</li>
                    <li>Baum-Welch expectation maximization
                      <ul>
                        <li>Maximum likelihood estimate </li>
                      </ul>
                    </li>
                  </ol>
                </li>
              </ul>
            </ul>
          </section>
        </section>
        <section>
          <section>
          <h2>Pose Gesture</h2>
          <img src="media/single_state.jpg"/>
          </section>
          <section>
            <h2>Pose Gesture</h2>
            <ul>
              <li>Training strategies
              <ul>
                <li>Expectation-maximiation for GMM</li>
                <li>Use Bayesian Information Criterion (BIC) to choose the number of mixtures.</li>
              </ul>
              </li>
            </ul>
          </section>
        </section>
        <section>
          <section data-transition="none">
          <h2>Combined and Flattened HMM</h2>
          <img src="media/hmms.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Combined and Flattened HMM</h2>
          <img src="media/combined_hmm1.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Combined and Flattened HMM</h2>
          <img src="media/combined_hmm2.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Combined and Flattened HMM</h2>
          <img src="media/combined_hmm.jpg"/>
          </section>
        </section>
        <section>
          <section data-transition="none">
          <h2>Online Inference</h2>
          <img src="media/classification.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Online Inference</h2>
          <img src="media/filtering.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Online Inference</h2>
          <img src="media/fixed_lag.jpg"/>
          </section>
        </section>
        <section>
          <section data-transition="none">
            <h2>Fixed-Lag Smoothing</h2>
            <img src="media/forward1.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Fixed-Lag Smoothing</h2>
            <img src="media/forward2.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Fixed-Lag Smoothing</h2>
            <img src="media/forward3.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Fixed-Lag Smoothing</h2>
            <img src="media/backward.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Fixed-Lag Smoothing</h2>
            <img src="media/gamma.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Fixed-Lag Smoothing</h2>
            <img src="media/gamma2.jpg"/>
          </section>
          <section data-transition="none">
            <h2>Fixed-Lag Smoothing</h2>
            <ul>
              <li>Time complexity: \(O(H^2l)\)</li>
              <li>Space complexity: \(O(Hl)\)</li>
            </ul>
          </section>
        </section>
        <section>
          <video muted preload="auto">
          <source src="media/video/dataset.mp4" type="video/mp4"> 
          </video>
        </section>
        <section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Discrete Flow</h2>
          <img src="media/circle1.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Discrete Flow</h2>
          <img src="media/circle2.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Discrete Flow</h2>
          <img src="media/circle3.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Discrete Flow</h2>
          <img src="media/circle4.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Discrete Flow</h2>
          <img src="media/circle5.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Discrete Flow</h2>
          <img src="media/circle6.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Continuous Flow</h2>
          <img src="media/point1.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Continuous Flow</h2>
          <img src="media/point2.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Continuous Flow</h2>
          <img src="media/point3.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Simultaneous Segmentation and Recognition - Continuous Flow</h2>
          <img src="media/point4.jpg"/>
          </section>
        </section>
        <section>
          <h2>Evaluation</h2>
          <ul>
            <li>Hybrid performance metrics</li>
              <ul>
                <li>Event based metric for discrete flow gestures</li>
                <li>Frame based metric for continuous flow gestures</li>
              </ul>
          </ul>
        </section>
        <section>
          <section data-transition="none">
          <h2>Compare Different Topologies</h2>
          <img src="media/topology.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Compare Different Topologies</h2>
          <img src="media/topology2.jpg"/>
          </section>
          <section data-transition="none">
          <h2>Compare Different Topologies</h2>
          <img src="media/topology3.jpg"/>
          </section>
        </section>
        <section>
          <h2>Effect of Lag Time</h2>
          <img src="media/f1_lag.png"/>
        </section>
        <section>
          <h2>Future Work</h2>
          <ul>
            <li>Two-hand gestures</li>
            <li>Improve pose gesture recognition</li>
            <li>Improve user independent base model</li>
          </ul>
        </section>
        <section>
        <h2>Contributions</h2>
        <ul>
          <li>Human computer interaction
            <ul>
              <li>Smoothly handles <em>path</em> and <em>pose</em> gestures</li>
              <li>Responds to <em>discrete</em> and <em>continous</em> flow gestures appropriately and promptly</li>
            </ul>
          </li>
          <li>Machine learning
            <ul>
              <li>Probabilistic model that unifies recognition of two forms of gestures</li>
              <li>Use hidden states to identify gesture phases</li>
              <li>Efficient online inference to achieve a balance between accuracy and responsiveness</li>
            </ul>
          </li>
          <li class="fragment">Other work
            <ul>
              <li>Gesture spotting [ICMI'13]</li>
              <li>User adaptation for touchscreen input [CHI'13]</li>
            </ul>
          </li>
        </ul>
        </section>
        <section>
          <h2>Acknowledgements</h2>
        </section>
      </div>
    </div>
    <script src="js/reveal.min.js"></script>
    <script src="js/head.min.js"></script>
    <script>
      Reveal.initialize({
        slideNumber: true,

        math: {
          mathjax: "plugin/math/MathJax.js",
          config: "TeX-AMS_HTML"
        },

        dependencies: [
          { src: "plugin/math/math.js", async: true }
        ],

        gesture: {
          mirror: true,
          autoCenter: true
        }
      });
    </script>
  </body>
</html>
